<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Focusing on security of AI, and distributed AI."><title>pytorch 回归分类常用函数 | realyee's blog</title><link rel="stylesheet" type="text/css" href="/blog/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/blog/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/blog/favicon.ico"><link rel="apple-touch-icon" href="/blog/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/blog/apple-touch-icon.png"><script src="https://www.googletagmanager.com/gtag/js?id=G-HT3KXNPC43" async></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-HT3KXNPC43');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement('script');
  hm.src = 'https://hm.baidu.com/hm.js?' + '81692a5a3ea48096c98733a7d4bfef6b';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();</script><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><div class="darkmode-toggle">🌓</div><script>var prefersDarkMode = window.matchMedia('(prefers-color-scheme: dark)');
var toggle = document.querySelector('.darkmode-toggle');
var html = document.querySelector('html');

html.dataset.dark = localStorage.dark || prefersDarkMode.matches;

toggle.addEventListener('click', () => {
localStorage.dark = !(html.dataset.dark == 'true');
html.dataset.dark = localStorage.dark;
});</script><meta name="generator" content="Hexo 6.3.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">pytorch 回归分类常用函数</h1><a id="logo" href="/blog/.">realyee's blog</a><p class="description">Security and privacy of AI, and distributed AI, Cybersecurity</p></div><div id="nav-menu"><a class="current" href="/blog/."><i class="fa fa-home"> Home</i></a><a href="/blog/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/blog/tags/"><i class="fa fa-tag"> Tags</i></a><a href="/blog/history/"><i class="fa fa-book"> History</i></a><a href="/blog/cheatsheet/"><i class="fa fa-user"> Cheatsheet</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">pytorch 回归分类常用函数</h1><div class="post-meta">2023-02-15<span> | </span><span class="category"><a href="/blog/categories/blockchain/">blockchain</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 2.1k</span><span class="post-meta-item-text"> Words</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 9</span><span class="post-meta-item-text"> Minutes</span></span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">Contents</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#torch-%E8%AE%AD%E7%BB%83%E7%9B%B8%E5%85%B3"><span class="toc-number">1.</span> <span class="toc-text">torch 训练相关</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#pytorch-%E4%BD%BF%E7%94%A8-gpu"><span class="toc-number">1.1.</span> <span class="toc-text">Pytorch 使用 GPU</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tensor-%E5%9C%A8-cpu-%E4%B8%8E-gpu-%E4%B9%8B%E9%97%B4"><span class="toc-number">2.</span> <span class="toc-text">tensor 在 cpu 与 gpu 之间</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#model.train-%E5%92%8C-model.eval"><span class="toc-number">2.1.</span> <span class="toc-text">model.train() 和 model.eval()</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%9F%A5%E8%AF%86"><span class="toc-number">3.</span> <span class="toc-text">小知识</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%8D%E5%88%B6%E5%88%9B%E5%BB%BA%E7%8B%AC%E7%AB%8B%E6%96%B0%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.</span> <span class="toc-text">复制创建独立新模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#numpy-%E5%92%8C-torch-%E7%9A%84-%E7%9F%A9%E9%98%B5%E4%B9%98"><span class="toc-number">5.</span> <span class="toc-text">numpy 和 torch 的 矩阵乘</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#jupyter-notebook-%E7%BC%93%E5%AD%98%E9%97%AE%E9%A2%98"><span class="toc-number">6.</span> <span class="toc-text">jupyter notebook 缓存问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%A4%E5%8F%89%E7%86%B5"><span class="toc-number">7.</span> <span class="toc-text">交叉熵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#nn.parameter-%E5%88%9D%E5%A7%8B%E5%8C%96%E5%9C%A8-gpu-%E8%AE%BE%E5%A4%87%E4%B8%8A"><span class="toc-number">8.</span> <span class="toc-text">nn.Parameter 初始化在 GPU
设备上</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#softmax-%E5%92%8C-sigmoid"><span class="toc-number">9.</span> <span class="toc-text">softmax 和 sigmoid</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#binary-crossentropy-related"><span class="toc-number">10.</span> <span class="toc-text">binary crossentropy related</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#soft-targets-vs-hard-target"><span class="toc-number">11.</span> <span class="toc-text">soft targets vs hard target</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mnist-softmax-logistic-regression-%E5%8F%82%E6%95%B0"><span class="toc-number">12.</span> <span class="toc-text">MNIST softmax logistic
regression 参数</span></a></li></ol></div></div><div class="post-content"><h2 id="torch-训练相关">torch 训练相关</h2>
<h3 id="pytorch-使用-gpu">Pytorch 使用 GPU</h3>
<ol type="1">
<li><p>设备转换</p>
<p>2 things must be on GPU: model, tensors, 处于同设备（CPU 或
GPU）的数据才能够互相运算，否则需要转换到同一设备</p>
<p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># For nvidia GPU</span><br><span class="line">cuda_device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line"></span><br><span class="line"># For arm-based Apple M1&#x27;s GPU</span><br><span class="line">device = torch.device(&quot;mps&quot; if torch.backends.mps.is_available() else &quot;cpu&quot;)</span><br><span class="line"></span><br><span class="line">cpu_device = torch.device(&quot;cpu&quot;)</span><br><span class="line"></span><br><span class="line"># use case</span><br><span class="line">model = model.to(cuda_device)</span><br><span class="line">tensor = tensor.to(device)</span><br><span class="line">model = model.to(cpu_device)</span><br></pre></td></tr></table></figure></p>
<p><a
target="_blank" rel="noopener" href="https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_logistic_regression/#building-a-logistic-regression-model-with-pytorch-gpu">Logistic
Regression - Deep Learning Wizard</a></p></li>
<li><p><code>torch.cuda()</code> 和
<code>tensor.to(torch.device("cuda"))</code> 区别</p>
<blockquote>
<p>Early versions of pytorch had <code>.cuda()</code> and
<code>.cpu()</code> methods to move tensors and models from cpu to gpu
and back. However, this made code writing a bit cumbersome. Later
versions introduced <code>.to()</code> that basically takes care of
everything in an elegant way:</p>
</blockquote>
<p><a
target="_blank" rel="noopener" href="https://stackoverflow.com/questions/62907815/pytorch-what-is-the-difference-between-tensor-cuda-and-tensor-totorch-device">python
- PyTorch: What is the difference between tensor.cuda() and
tensor.to(torch.device("cuda:0"))? - Stack Overflow</a></p>
<p>推荐使用新版的 <code>tensor.to(torch.device("cuda"))</code></p></li>
</ol>
<p>注意：<code>tensor.to()</code> 执行的不是 inplace
操作，因此需要赋值；<code>module.to()</code> 执行的是 inplace 操作。</p>
<h2 id="tensor-在-cpu-与-gpu-之间">tensor 在 cpu 与 gpu 之间</h2>
<ol type="1">
<li><p>想要修改模型参数，然后继续使用：</p>
<ol type="1">
<li>将其从 gpu 拷贝一份，使用： <code>.cpu().detach()</code> 返回 tensor
形式 或 <code>.cpu().detach().numpy()</code> 返回 numpy 形式</li>
<li>然后，对 tensor 或者 numpy 进行修改 最后，将 CPU 中修改的
tensor（numpy 需要转换为 tensor）拷贝到 gpu 中去：.cuda() 或
.to(device=torch.device('gpu'))</li>
</ol>
<p>即使 copy.deepcopy 了 tensor， tensor 也是在 gpu 中的，需要转到
cpu</p>
<p><a
href="https://%20androidkt.com/copy-pytorch-model-using-deepcopy-and-state_dict/">Copy
PyTorch Model using deepcopy() and state_dict() - Knowledge Transfer</a>
<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/91485607">Pytorch 的 12 个坑 -
知乎</a></p></li>
</ol>
<h3 id="model.train-和-model.eval">model.train() 和 model.eval()</h3>
<p><code>model.train()</code>: 在使用 pytorch
构建神经网络的时候，训练过程中会在程序上方添加一句
model.train()，作用是启用 batch normalization 和 drop out。</p>
<p><code>model.eval()</code>: 测试过程中会使用
model.eval()，这时神经网络会沿用 batch normalization 的值，并不使用 drop
out。</p>
<p>如果模型中有 BN 层 (Batch Normalization)和 Dropout，需要在训练时添加
<code>model.train()</code>，在测试时添加 <code>model.eval()</code>。其中
model.train()是保证 BN 层用每一批数据的均值和方差，而
<code>model.eval()</code> 是保证 BN 用全部训练数据的均值和方差；而对于
Dropout，model.train()是随机取一部分网络连接来训练更新参数，而
<code>model.eval()</code> 是利用到了所有网络连接。</p>
<p>如果没有 BN 层 (Batch Normalization)和 Dropout
这两种层，就不用写了。</p>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/a/66526891">python - What does
model.train() do in PyTorch? - Stack Overflow</a> <a
target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/254738836">[PyTorch 学习笔记] 7.3
使用 GPU 训练模型 - 知乎</a></p>
<h2 id="小知识">小知识</h2>
<ol type="1">
<li><p><code>Loss.item()</code></p>
<p>The <code>.item()</code> method extracts the loss’s value as a Python
float, so that you can do some operations, such as sum and average
operations.</p>
<p><code>.item()</code> moves the data to CPU. It converts or extracts
the loss’s value as a Python float. and the plain python float number
can only live on the CPU.</p>
<p><a target="_blank" rel="noopener" href="https://discuss.pytorch.org/t/what-is-loss-item/61218">What
is loss.item() - autograd - PyTorch Forums</a></p></li>
<li><p>In Pytorch, when dataset = cifar, the type(dataset.targets) is
list</p>
<p>注意 pytorch 读取 MNIST 读出来的 <code>dataset.targets</code> 是
Tensor，但是读取 CIFAR10 读取出来的不是 Tensor，而是 list.
统一训练的时候，注意判断</p></li>
<li><p>Time</p>
<p>CPU 跑 MNIST 多分类逻辑回归： 6 min 左右 GPU 跑 MNIST
多分类逻辑回归： 1min30 min 左右</p></li>
<li><p>accuracy</p>
<ol type="1">
<li>a binary classification model using logistic regression on MNIST can
converges to 98% accuracy</li>
<li>a multi-class classification model using logistic regression on
MNIST can converges to 92% accuracy</li>
</ol>
<p>参考： <a
target="_blank" rel="noopener" href="https://stackoverflow.com/questions/45954289/logistic-regression-implementation-with-mnist-not-converging">python
- Logistic Regression implementation with MNIST - not converging? -
Stack Overflow</a></p></li>
</ol>
<h2 id="复制创建独立新模型">复制创建独立新模型</h2>
<pre><code>The PyTorch model 是可变对象，因此直接赋值是浅拷贝，需要使用 `copy.deepcopy()` 或者 `model.state_dict()` 来进行深拷贝。

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import copy</span><br><span class="line">modelB = copy.deepcopy(modelA)</span><br></pre></td></tr></table></figure>

[Copy PyTorch Model using deepcopy() and state_dict() - Knowledge Transfer](https://androidkt.com/copy-pytorch-model-using-deepcopy-and-state_dict/)</code></pre>
<h2 id="numpy-和-torch-的-矩阵乘">numpy 和 torch 的 矩阵乘</h2>
<p>两个矩阵相乘： <code>np.dot(A,B)</code> 或者
<code>np.matmul(A, B)</code> 多个矩阵相乘： 每两个使用 <code>dot</code>
或者 <code>matmul</code> 或直接使用 <code>@</code> 符号 对应元素相乘：
<code>np.multiply</code> 或者 <code>*</code></p>
<p><code>torch.mul()</code>
是对应元素相乘（可广播），<code>torch.mm()</code> 是矩阵相乘 <a
target="_blank" rel="noopener" href="https://blog.51cto.com/u_15127604/3856291">torch.mul() 和
torch.mm() 区别_mob604756f6df2a 的技术博客_51CTO 博客</a></p>
<h2 id="jupyter-notebook-缓存问题">jupyter notebook 缓存问题</h2>
<ol type="1">
<li><p>在外部更改了调用的函数的代码，但是它依然使用旧的缓存的代码，解决方法：</p>
<p>Put in the following two cells at the beggining of your code and it
will automatically reload any new version of your code:</p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">%load_ext autoreload</span><br><span class="line">%autoreload <span class="number">2</span></span><br></pre></td></tr></table></figure></p>
<p><a
target="_blank" rel="noopener" href="https://stackoverflow.com/questions/29353600/ipython-notebook-caching-issue">python
- Ipython notebook caching issue - Stack Overflow</a></p></li>
</ol>
<h2 id="交叉熵">交叉熵</h2>
<p>交叉熵预测结果的概率矩阵，求预测概率最大的值，可以使用的函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.<span class="built_in">max</span>(<span class="built_in">input</span>, dim, keepdim=<span class="literal">False</span>) 返回 (<span class="built_in">max</span>, max_indices)</span><br><span class="line">torch.argmax(<span class="built_in">input</span>, dim, keepdim=<span class="literal">False</span>) 返回 max_indices</span><br></pre></td></tr></table></figure>
<p>常见形式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">outputs = model(images)</span><br><span class="line">_, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>或</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">outputs = model(images)</span><br><span class="line">predicted = outputs.argmax(dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="nn.parameter-初始化在-gpu-设备上">nn.Parameter 初始化在 GPU
设备上</h2>
<p><a
target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/issues/20089">[Undesirable
behaviour] Allocating a nn.Parameter on gpu inside a nn.Module makes it
not to be enlisted as network parameter · Issue #20089 ·
pytorch/pytorch</a></p>
<h2 id="softmax-和-sigmoid">softmax 和 sigmoid</h2>
<table>
<colgroup>
<col style="width: 7%" />
<col style="width: 49%" />
<col style="width: 43%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">激活函数</th>
<th style="text-align: center;">sigmoid</th>
<th style="text-align: center;">softmax</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">分类</td>
<td
style="text-align: center;">一般用于二值分类，可以但不建议用于多值分类，准确率低</td>
<td style="text-align: center;">可以用于二值以及多值分类</td>
</tr>
<tr class="even">
<td style="text-align: center;">使用注意</td>
<td style="text-align: center;">分类不明确的，概率性的，使用
sigmoid</td>
<td style="text-align: center;">分类互斥，可以明确输出是哪个类别的使用
softmax</td>
</tr>
<tr class="odd">
<td style="text-align: center;">交叉熵</td>
<td style="text-align: center;">BCE: binary cross-entropy</td>
<td style="text-align: center;">categorical cross-entropy</td>
</tr>
</tbody>
</table>
<p><a
target="_blank" rel="noopener" href="https://stackoverflow.com/questions/49990816/sigmoid-activation-for-multi-class-classification">machine
learning - Sigmoid activation for multi-class classification? - Stack
Overflow</a></p>
<p><a
target="_blank" rel="noopener" href="https://datascience.stackexchange.com/questions/39264/how-does-sigmoid-activation-work-in-multi-class-classification-problems">machine
learning - How does Sigmoid activation work in multi-class
classification problems - Data Science Stack Exchange</a></p>
<h2 id="binary-crossentropy-related">binary crossentropy related</h2>
<p><code>torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')</code>:
weight 是 sigmoid 预测的类别概率，If given, has to be
<code>a Tensor of size nbatch</code>: [batch_size,
number_class]，（需要梯度，float 类别） <code>'reduction='mean'</code>:
the sum of the output will be divided by the number of elements in the
output.</p>
<p><code>nn.BCEWithLogitsLoss()</code> 封装了 sigmoid
所以直接把模型的输入传进去即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.empty(<span class="number">3</span>).random_(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">sigmoid = nn.Sigmoid()</span><br><span class="line">bce_loss = nn.BCELoss()</span><br><span class="line">bce_logits_loss = nn.BCEWithLogitsLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment">#with class probabilities</span></span><br><span class="line">probabilities=sigmoid(<span class="built_in">input</span>)</span><br><span class="line">output = bce_loss(probabilities, target)</span><br><span class="line">output.backward()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(output.item()) <span class="comment">#0.4326</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#with logits</span></span><br><span class="line">output = bce_logits_loss(<span class="built_in">input</span>, target)</span><br><span class="line">output.backward()</span><br></pre></td></tr></table></figure>
<p><a
target="_blank" rel="noopener" href="https://zhang-yang.medium.com/how-is-pytorchs-binary-cross-entropy-with-logits-function-related-to-sigmoid-and-d3bd8fb080e7">How
is Pytorch’s binary_cross_entropy_with_logits function related to
sigmoid and binary_cross_entropy | by Yang Zhang | Medium</a></p>
<p><a
target="_blank" rel="noopener" href="https://androidkt.com/difference-between-bceloss-and-bcewithlogitsloss-in-pytorch/">Difference
between BCELoss and BCEWithLogitsLoss in PyTorch - Knowledge
Transfer</a></p>
<h2 id="soft-targets-vs-hard-target">soft targets vs hard target</h2>
<p>soft targets 就是 softmax 得出的各类的概率 一般使用 soft target 的
loss function</p>
<p>hard target 包含的信息量（信息熵）很低， soft target
包含的信息量大，拥有不同类之间关系的信息（比如同时分类驴和马的时候，尽管某张图片是马，但是
soft target 就不会像 hard target 那样只有马的 index 处的值为 1，其余为
0，而是在驴的部分也会有概率。）</p>
<h2 id="mnist-softmax-logistic-regression-参数">MNIST softmax logistic
regression 参数</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">Model: &quot;sequential&quot;</span><br><span class="line">mathjax: true</span><br><span class="line">---Layer (type) Output Shape Param #</span><br><span class="line">mathjax: true</span><br><span class="line">---flatten (Flatten) (None, 784) 0</span><br><span class="line">mathjax: true</span><br><span class="line">---dense (Dense) (None, 10) 7850</span><br><span class="line">---</span><br><span class="line">Total params: 7,850</span><br><span class="line">Trainable params: 7,850</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">mathjax: true</span><br><span class="line">---```</span><br><span class="line"></span><br><span class="line">parameters: `784*10 weights + 10 biases at output nodes = 7850`</span><br><span class="line"></span><br><span class="line">每张图像的输出都是一个大小为 10 的向量，该向量的每个元素都指示了该图像属于某个具体标签（0 到 9）的概率。为图像预测得到的标签即为概率最高的标签。</span><br><span class="line"></span><br><span class="line">[Feed-forward and convolutional neural networks](https://uudav.nl/practicals/04_deep_learning/practical_04_answers.html)</span><br><span class="line"></span><br><span class="line">## 多分类/二分类</span><br><span class="line"></span><br><span class="line">对 crossentropy 输出的概率，求最大的值及其索引: `_, preds = torch.max(outputs, 1)`</span><br><span class="line"></span><br><span class="line">At this point, we need to determine the index corresponding to the maximum score in the out tensor. We can do that using the max function in PyTorch, which outputs the maximum value in a tensor as well as the indices where that maximum value occurred.</span><br><span class="line"></span><br><span class="line">## [conv neural network - ValueError: Target size (torch.Size([16])) must be the same as input size (torch.Size([16, 1])) - Stack Overflow](https://stackoverflow.com/questions/57798033/valueerror-target-size-torch-size16-must-be-the-same-as-input-size-torch)</span><br><span class="line"></span><br><span class="line">pytorch 二分类 using BCEWithLogitsLoss， output neuron = 1, `preds.squeeze(dim=-1).float()`</span><br><span class="line"></span><br><span class="line">### 二分类测试</span><br><span class="line"></span><br><span class="line">sigmoid 二分类，测试准确度时，注意预测概率是 [0,1]，所以将其与 0.5 进行比较</span><br><span class="line">`predicted = (model(image) &gt; 0.5).float().squeeze(dim=-1)`</span><br><span class="line"></span><br><span class="line">softmax 二分类，测试准确度时，注意预测概率是 [-inf,inf]，所以需要将其与 0 比较</span><br><span class="line">`predicted = (model(image) &gt; 0).float().squeeze(dim=-1)`</span><br><span class="line"></span><br><span class="line">[Accuracy not changing after second training epoch - PyTorch Forums](https://discuss.pytorch.org/t/accuracy-not-changing-after-second-training-epoch/80405/3)</span><br><span class="line"></span><br><span class="line"># accuracy 先稳定上升，然后一直降低</span><br><span class="line"></span><br><span class="line">学习率过大/batch size 过小，可以对学习率降低 1-2 个量级试试</span><br><span class="line">[训练网络时为什么会出现 loss 逐渐增大的情况？ - 知乎](https://www.zhihu.com/question/60510992)02</span><br><span class="line"></span><br><span class="line">## 准确率先升后降，再升</span><br><span class="line"></span><br><span class="line">采用 warm up + Cosine Anneal：</span><br><span class="line"></span><br><span class="line">[训练神经网络 Loss 先降后升？ - 简书](https://www.jianshu.com/p/c8583867677e)</span><br><span class="line">[base model 第七弹：warm up、consine 衰减 、标签平滑、apex、梯度累加 - 知乎](https://zhuanlan.zhihu.com/p/148487894)</span><br><span class="line"></span><br><span class="line">[使用余弦退火逃离局部最优点——快照集成(Snapshot Ensembles)在 Keras 上的应用 - 知乎](https://zhuanlan.zhihu.com/p/93648558)</span><br><span class="line"></span><br><span class="line">[Pytorch：几行代码轻松实现 Warm up + Cosine Anneal LR\_我是大黄同学呀的博客-CSDN 博客\_pytorch warmup 实现](https://blog.csdn.net/qq_36560894/article/details/114004799)</span><br><span class="line"></span><br><span class="line">[调节学习率 - 知乎](https://zhuanlan.zhihu.com/p/136183319)</span><br></pre></td></tr></table></figure>
</div><div class="tags"></div><div class="post-nav"><a class="pre" href="/blog/2023/02/15/programming/python/pytorch/torch_dataset/">torch dataset 相关函数</a><a class="next" href="/blog/2023/01/04/linux/linux_issues/">Linux 常见问题</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/" title=""><img class="nofancybox" src="/blog/img/avatar.png"/></a><p>What keeps me alive is my love for people and life and my desire to explore the unknown</p><a class="info-icon" href="mailto:findrealyee@outlook.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/realyee/" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/blog/categories/Cryptography/">Cryptography</a><span class="category-list-count">29</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/blog/categories/Cryptography/math/">math</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/Cryptography/zero-knowledge-proof/">zero-knowledge proof</a><span class="category-list-count">20</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/Golang/">Golang</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/academic/">academic</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/blockchain/">blockchain</a><span class="category-list-count">25</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/cplusplus/">cplusplus</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/go/">go</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/linux/">linux</a><span class="category-list-count">34</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/blog/categories/linux/git/">git</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/linux/macos/">macos</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/linux/tools/">tools</a><span class="category-list-count">12</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/misc/">misc</a><span class="category-list-count">16</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/blog/categories/misc/latex/">latex</a><span class="category-list-count">5</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/ml/">ml</a><span class="category-list-count">27</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/blog/categories/ml/rl/">rl</a><span class="category-list-count">4</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/network/">network</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/os/">os</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/php/">php</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/probabilities/">probabilities</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/python/">python</a><span class="category-list-count">64</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/security-miscellaneous/">security miscellaneous</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/shell/">shell</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/utilities/">utilities</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/websec/">websec</a><span class="category-list-count">35</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/blog/categories/websec/cmd-execution/">cmd_execution</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/websec/file-upload/">file_upload</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/websec/logic-vuln/">logic_vuln</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/websec/sql-injection/">sql injection</a><span class="category-list-count">21</span></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/websec/xss/">xss</a><span class="category-list-count">3</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/wireshark/">wireshark</a><span class="category-list-count">7</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/blog/tags/academic/" style="font-size: 15px;">academic</a> <a href="/blog/tags/sci/" style="font-size: 15px;">sci</a> <a href="/blog/tags/jcr/" style="font-size: 15px;">jcr</a> <a href="/blog/tags/ml/" style="font-size: 15px;">ml</a> <a href="/blog/tags/cuda/" style="font-size: 15px;">cuda</a> <a href="/blog/tags/misc/" style="font-size: 15px;">misc</a> <a href="/blog/tags/vscode/" style="font-size: 15px;">vscode</a> <a href="/blog/tags/threat-intelligence/" style="font-size: 15px;">threat intelligence</a> <a href="/blog/tags/typing/" style="font-size: 15px;">typing</a> <a href="/blog/tags/distance/" style="font-size: 15px;">distance</a> <a href="/blog/tags/osi-sec/" style="font-size: 15px;">osi_sec</a> <a href="/blog/tags/smtp/" style="font-size: 15px;">smtp</a> <a href="/blog/tags/mail/" style="font-size: 15px;">mail</a> <a href="/blog/tags/Boot/" style="font-size: 15px;">Boot</a> <a href="/blog/tags/Computer/" style="font-size: 15px;">Computer</a> <a href="/blog/tags/FAT/" style="font-size: 15px;">FAT</a> <a href="/blog/tags/FDT/" style="font-size: 15px;">FDT</a> <a href="/blog/tags/os/" style="font-size: 15px;">os</a> <a href="/blog/tags/efi/" style="font-size: 15px;">efi</a> <a href="/blog/tags/Python/" style="font-size: 15px;">Python</a> <a href="/blog/tags/Tools/" style="font-size: 15px;">Tools</a> <a href="/blog/tags/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/" style="font-size: 15px;">网络协议</a> <a href="/blog/tags/Wireshark%E5%8A%9F%E8%83%BD/" style="font-size: 15px;">Wireshark功能</a> <a href="/blog/tags/%E6%B8%97%E9%80%8F/" style="font-size: 15px;">渗透</a> <a href="/blog/tags/%E6%8A%93%E5%8C%85/" style="font-size: 15px;">抓包</a> <a href="/blog/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">计算机网络</a> <a href="/blog/tags/zkp/" style="font-size: 15px;">zkp</a> <a href="/blog/tags/circom/" style="font-size: 15px;">circom</a> <a href="/blog/tags/git/" style="font-size: 15px;">git</a> <a href="/blog/tags/ssh/" style="font-size: 15px;">ssh</a> <a href="/blog/tags/arch/" style="font-size: 15px;">arch</a> <a href="/blog/tags/manjaro/" style="font-size: 15px;">manjaro</a> <a href="/blog/tags/chmod/" style="font-size: 15px;">chmod</a> <a href="/blog/tags/ping/" style="font-size: 15px;">ping</a> <a href="/blog/tags/network/" style="font-size: 15px;">network</a> <a href="/blog/tags/find/" style="font-size: 15px;">find</a> <a href="/blog/tags/head/" style="font-size: 15px;">head</a> <a href="/blog/tags/tail/" style="font-size: 15px;">tail</a> <a href="/blog/tags/ioredirect/" style="font-size: 15px;">ioredirect</a> <a href="/blog/tags/pipe/" style="font-size: 15px;">pipe</a> <a href="/blog/tags/fd/" style="font-size: 15px;">fd</a> <a href="/blog/tags/iproute2/" style="font-size: 15px;">iproute2</a> <a href="/blog/tags/kill/" style="font-size: 15px;">kill</a> <a href="/blog/tags/hardlink/" style="font-size: 15px;">hardlink</a> <a href="/blog/tags/softlink/" style="font-size: 15px;">softlink</a> <a href="/blog/tags/netstat/" style="font-size: 15px;">netstat</a> <a href="/blog/tags/ss/" style="font-size: 15px;">ss</a> <a href="/blog/tags/lsof/" style="font-size: 15px;">lsof</a> <a href="/blog/tags/traceroute/" style="font-size: 15px;">traceroute</a> <a href="/blog/tags/vim/" style="font-size: 15px;">vim</a> <a href="/blog/tags/latex/" style="font-size: 15px;">latex</a> <a href="/blog/tags/CNN/" style="font-size: 15px;">CNN</a> <a href="/blog/tags/convolution/" style="font-size: 15px;">convolution</a> <a href="/blog/tags/CMake/" style="font-size: 15px;">CMake</a> <a href="/blog/tags/Make/" style="font-size: 15px;">Make</a> <a href="/blog/tags/php/" style="font-size: 15px;">php</a> <a href="/blog/tags/python/" style="font-size: 15px;">python</a> <a href="/blog/tags/re/" style="font-size: 15px;">re</a> <a href="/blog/tags/Regexp/" style="font-size: 15px;">Regexp</a> <a href="/blog/tags/shell/" style="font-size: 15px;">shell</a> <a href="/blog/tags/mysql/" style="font-size: 15px;">mysql</a> <a href="/blog/tags/pseudo-static/" style="font-size: 15px;">pseudo static</a> <a href="/blog/tags/sql-injection/" style="font-size: 15px;">sql injection</a> <a href="/blog/tags/XSS/" style="font-size: 15px;">XSS</a> <a href="/blog/tags/collection/" style="font-size: 15px;">collection</a> <a href="/blog/tags/collections/" style="font-size: 15px;">collections</a> <a href="/blog/tags/comprehensions/" style="font-size: 15px;">comprehensions</a> <a href="/blog/tags/fun/" style="font-size: 15px;">fun</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/blog/2023/09/18/ml/wasserstein_dist/">Delve into Wasserstein Distance, principles and implementation analysis</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2023/09/17/math/probabilities/wasserstein_bg/">Probabilities background for Wasserstein Distance</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2023/08/11/academic/papers/ldp_location/">L-SRR Local Differential Privacy for Location-Based Services with Staircase Randomized Response</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2023/08/10/academic/papers/ldp_byz_fl/">Practical Differentially Private and Byzantine-resilient Federated Learning</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2023/08/04/academic/papers/fedrecover/">FedRecover 论文阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2023/08/04/academic/papers/flcert/">FLCert Provably Secure Federated Learning against Poisoning Attacks 论文阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2023/08/04/academic/papers/fltrust/">FLTrust Byzantine-robust Federated Learning via Trust Bootstrapping 论文阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2023/05/30/crypto/zk/specific2program/">zk with programmability</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2023/04/30/crypto/zk/great_resource/">zk 资料汇总</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2023/04/16/misc/latex/latex_grammars/">常用 LaTeX 语法总结</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://snowolf0620.xyz/" title="snowolf0620" target="_blank">snowolf0620</a><ul></ul><a href="https://space.keter.top/" title="Sonder" target="_blank">Sonder</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2024 <a href="/blog/." rel="nofollow">realyee's blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/blog/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/blog/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="/blog/css/search.css?v=1.0.0"><script type="text/javascript" src="/blog/js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
  search_path = 'search.xml';
}
var path = '/blog/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/blog/js/copycode.js?v=1.0.0" successtext="Copy Successed!"></script><link rel="stylesheet" type="text/css" href="/blog/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/blog/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/blog/js/smartresize.js?v=1.0.0"></script></div></body></html>